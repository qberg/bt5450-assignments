{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "neural-austin",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Supervised-Learning\" data-toc-modified-id=\"Supervised-Learning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Supervised Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Derivation-of-Naive-Bayes-Posterior-Probability\" data-toc-modified-id=\"Derivation-of-Naive-Bayes-Posterior-Probability-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Derivation of Naive Bayes Posterior Probability</a></span><ul class=\"toc-item\"><li><span><a href=\"#Role-of-Priors-in-Naive-Bayes-Classifier\" data-toc-modified-id=\"Role-of-Priors-in-Naive-Bayes-Classifier-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Role of Priors in Naive Bayes Classifier</a></span></li></ul></li><li><span><a href=\"#Implementation-of-Naive-Bayes-Classifier\" data-toc-modified-id=\"Implementation-of-Naive-Bayes-Classifier-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Implementation of Naive Bayes Classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fitting-the-model-using-two-features\" data-toc-modified-id=\"Fitting-the-model-using-two-features-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Fitting the model using two features</a></span></li><li><span><a href=\"#Fitting-the-model-using-all-features\" data-toc-modified-id=\"Fitting-the-model-using-all-features-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Fitting the model using all features</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-design",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-protection",
   "metadata": {},
   "source": [
    "## Derivation of Naive Bayes Posterior Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-westminster",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T14:58:04.148945Z",
     "start_time": "2021-09-01T14:58:04.133315Z"
    }
   },
   "source": [
    "* The various probablities involved are,\n",
    "\n",
    "    * **Posterior Probabiliry:** $P(Tt|x_1,x_2,\\dots,x_n)$\n",
    "    * **Likelihood:** $P(x_1,x_2,\\dots,x_n|Tt)$\n",
    "    * **Prior Probabiity:** $P(Tt)$\n",
    "---\n",
    "* Using the Bayes rule for conditional probabilities we can write,\n",
    "$$P(Tt|x_1,x_2,\\dots,x_n) = \\frac{P(x_1,x_2,\\dots,x_n|Tt)\\times P(Tt)}{P(x_1,x_2,\\dots,x_n)}$$\n",
    "* By independance,\n",
    "$$P(x_1,x_2,\\dots,x_n) = \\prod_{i=1}^{n} P(x_i)$$\n",
    "* The likelihood term can be manipulated using the chain rule and assumption of independant variables to give,\n",
    "$$P(x_1,x_2,\\dots,x_n|Tt) = \\prod_{i=1}^{n} P(x_i|Tt) $$\n",
    "* Combining all this we get,\n",
    "$$P(Tt|x_1,x_2,\\dots,x_n) = \\frac{\\prod_{i=1}^{n} P(x_i|Tt)\\times P(Tt)}{\\prod_{i=1}^{n} P(x_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-catholic",
   "metadata": {},
   "source": [
    "### Role of Priors in Naive Bayes Classifier\n",
    "\n",
    "* While building a classifier, we are interested in the posterior probablity calculated above. It can be defined as , given a sample test point what is the probability of it belonging to class Tt.\n",
    "* Therefore the classifications are made using argmax function for posterior probablity of the point belonging to various classes.\n",
    "* We can safely ignore the denominator for our decison rule, since it will be the same in all cases.\n",
    "* Thus,\n",
    "$$P(Tt|x_1,x_2,\\dots,x_n) \\propto \\prod_{i=1}^{n} P(x_i|Tt)\\times P(Tt)$$\n",
    "* As can be seen from the formula the prior plays an important role in classification.\n",
    "* When training a Naive Bayes Classifier, the prior probabilities are taken to be the frequency of occurences of samples belonging to the particular class in the training dataset.\n",
    "* Thus, if our training dataset has more samples belonging to a particular class, the corresponding prior probabilities will also be higher.\n",
    "* This will cause concerns if the number of training data points available for various classes is heavily skewed as there is a chance for the model to become biased towards the class with high prior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-dayton",
   "metadata": {},
   "source": [
    "## Implementation of Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confused-exposure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T15:31:35.025555Z",
     "start_time": "2021-09-01T15:31:34.430502Z"
    }
   },
   "outputs": [],
   "source": [
    "#Libraries to be used.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "uniform-primary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T15:31:35.047725Z",
     "start_time": "2021-09-01T15:31:35.025555Z"
    }
   },
   "outputs": [],
   "source": [
    "#Utilities to be used.\n",
    "pp = pprint.PrettyPrinter(width=60, depth=1)\n",
    "\n",
    "\n",
    "#A class that helps with processing the csv files.\n",
    "class process_csv:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.features = []\n",
    "\n",
    "    def read_csv_to_df(self):\n",
    "        #A function that takes in csv files and returns a dataframe after some processing.\n",
    "        self.features = [*pd.read_csv(self.path, nrows=1)]\n",
    "        self.features.pop(\n",
    "            0)  #Removes the first coulmn since it is not a feature.\n",
    "        df = pd.read_csv(self.path, usecols=[col for col in self.features])\n",
    "        return df\n",
    "\n",
    "    def scale_features(self, df):\n",
    "        #A fucntion that scales the values in a dataframe.\n",
    "        df_scaled = df.apply(lambda seq: (seq.astype(float) - min(seq)) /\n",
    "                             (max(seq) - min(seq)),\n",
    "                             axis=0)\n",
    "        return df_scaled\n",
    "\n",
    "    def df_to_numpy(self, df, scaling):\n",
    "        #Converts a dataframe in to an numpy array.\n",
    "        df_scaled = self.scale_features(df)\n",
    "        if scaling:\n",
    "            return df_scaled.to_numpy()\n",
    "        else:\n",
    "            return df.to_numpy()\n",
    "\n",
    "    def select_class(self, class_name, no_of_features_is_two, scaling):\n",
    "        #A function that filters samples belonging to the malignant class from the training data.\n",
    "        df = self.read_csv_to_df()\n",
    "        label_for_class = (df['diagnosis'] == class_name)\n",
    "        if no_of_features_is_two:\n",
    "            class_df = df.loc[label_for_class,\n",
    "                              [\"concave points_worst\", \"radius_mean\"]]\n",
    "        else:\n",
    "            class_df = df.loc[label_for_class, self.features[3:]]\n",
    "        class_arr = self.df_to_numpy(class_df, scaling)\n",
    "        return class_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "diverse-princess",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T15:31:35.179228Z",
     "start_time": "2021-09-01T15:31:35.047725Z"
    }
   },
   "outputs": [],
   "source": [
    "#A class that performs classification using naive bayes.\n",
    "class Naive_Bayes_Classifier:\n",
    "    def __init__(self, X_train_M, X_train_B):\n",
    "        self.training_data = [X_train_M, X_train_B]\n",
    "        self.Classes = ['M', 'B']\n",
    "        self.params = dict((Class, {}) for Class in self.Classes)\n",
    "\n",
    "    def fit(self):\n",
    "        #A method that estimates the values of parameters from the training data.\n",
    "        #Unpacking the training data.\n",
    "        X_m, X_b = self.training_data\n",
    "        #List of various statisitical params as a list.\n",
    "        N = [X_m.shape[0], X_b.shape[0]]\n",
    "        arr_mean = [\n",
    "            np.mean(X_m, axis=0, dtype=np.float64),\n",
    "            np.mean(X_b, axis=0, dtype=np.float64)\n",
    "        ]\n",
    "        arr_std = [\n",
    "            np.std(X_m, axis=0, dtype=np.float64),\n",
    "            np.std(X_b, axis=0, dtype=np.float64)\n",
    "        ]\n",
    "        for Class in self.Classes:\n",
    "            class_index = self.Classes.index(Class)\n",
    "            self.params[Class]['Prior'] = N[class_index] / sum(N)\n",
    "            self.params[Class]['Mean'] = arr_mean[class_index]\n",
    "            self.params[Class]['Std'] = arr_std[class_index]\n",
    "        #return self.params\n",
    "\n",
    "    def log_likelihood(self, x, mu, sigma):\n",
    "        return np.sum(-np.log(sigma) - (x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Calculates probabilities for each class per sample and assigns the class with maximum probability\n",
    "        pred = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            sample = X_test[i, :]\n",
    "            logp_m = self.log_likelihood(\n",
    "                sample, self.params['M']['Mean'],\n",
    "                self.params['M'][\"Std\"]) + self.params['M'][\"Prior\"]\n",
    "            logp_b = self.log_likelihood(\n",
    "                sample, self.params['B']['Mean'],\n",
    "                self.params['B'][\"Std\"]) + self.params['B'][\"Prior\"]\n",
    "            if logp_m > logp_b:\n",
    "                pred.append('M')\n",
    "            else:\n",
    "                pred.append('B')\n",
    "        return pred\n",
    "\n",
    "    def pred_accuracy(self, test_data_dict):\n",
    "        correct_pred = 0\n",
    "        N = 0\n",
    "        for label, X_test in test_data_dict.items():\n",
    "            N += X_test.shape[0]\n",
    "            pred = self.predict(X_test)\n",
    "            correct_pred += pred.count(label)\n",
    "        pred_accuracy = (correct_pred / N) * 100\n",
    "        return pred_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-calibration",
   "metadata": {},
   "source": [
    "### Fitting the model using two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "institutional-puzzle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T15:31:35.279231Z",
     "start_time": "2021-09-01T15:31:35.179228Z"
    }
   },
   "outputs": [],
   "source": [
    "path_tr_csv = r\"Cancer_train.csv\"\n",
    "path_test_csv =  r\"Cancer_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protective-andrews",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T15:31:35.379266Z",
     "start_time": "2021-09-01T15:31:35.279231Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_model_get_acc(path_tr, path_test, num_of_features_is_2,scaling):\n",
    "    training_data = process_csv(path_tr)\n",
    "    class_M_tr_data_arr = training_data.select_class('M', num_of_features_is_2,scaling)\n",
    "    class_B_tr_data_arr = training_data.select_class('B', num_of_features_is_2,scaling)\n",
    "    test_data = process_csv(path_test)\n",
    "    class_M_test_data_arr = test_data.select_class('M', num_of_features_is_2,scaling)\n",
    "    class_B_test_data_arr = test_data.select_class('B', num_of_features_is_2,scaling)\n",
    "    #Fitting the model for two features.\n",
    "    classifier = Naive_Bayes_Classifier(class_M_tr_data_arr,\n",
    "                                        class_B_tr_data_arr)\n",
    "    classifier.fit()\n",
    "    #FInding the accuracy of the prediction using labelled test data.\n",
    "    test_data = {'M': class_M_test_data_arr, 'B': class_B_test_data_arr}\n",
    "    pred_accuracy = classifier.pred_accuracy(test_data)\n",
    "    return (round(pred_accuracy, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tribal-pregnancy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T15:31:35.595429Z",
     "start_time": "2021-09-01T15:31:35.379266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model fitted using two features(without scaling) is: 92.86\n"
     ]
    }
   ],
   "source": [
    "accuracy = fit_model_get_acc(path_tr_csv,\n",
    "                             path_test_csv,\n",
    "                             num_of_features_is_2=True,scaling=False)\n",
    "print('The accuracy of the model fitted using two features(without scaling) is:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desperate-sheet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T15:31:35.648901Z",
     "start_time": "2021-09-01T15:31:35.595429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model fitted using two features(with scaling) is: 72.86\n"
     ]
    }
   ],
   "source": [
    "accuracy = fit_model_get_acc(path_tr_csv,\n",
    "                             path_test_csv,\n",
    "                             num_of_features_is_2=True,scaling = True)\n",
    "print('The accuracy of the model fitted using two features(with scaling) is:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-ivory",
   "metadata": {},
   "source": [
    "### Fitting the model using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fundamental-polls",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T15:31:35.816638Z",
     "start_time": "2021-09-01T15:31:35.648901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model fitted using all features(without scaling) is: 90.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = fit_model_get_acc(path_tr_csv,\n",
    "                             path_test_csv,\n",
    "                             num_of_features_is_2=False,scaling= False)\n",
    "print('The accuracy of the model fitted using all features(without scaling) is:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chemical-distributor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T15:31:35.949673Z",
     "start_time": "2021-09-01T15:31:35.816638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model fitted using all features(with scaling) is: 62.86\n"
     ]
    }
   ],
   "source": [
    "accuracy = fit_model_get_acc(path_tr_csv,\n",
    "                             path_test_csv,\n",
    "                             num_of_features_is_2=False,scaling=True)\n",
    "print('The accuracy of the model fitted using all features(with scaling) is:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
